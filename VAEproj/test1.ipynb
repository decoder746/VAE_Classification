{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "'''Example of VAE on MNIST dataset using MLP\n",
    "\n",
    "The VAE has a modular design. The encoder, decoder and VAE\n",
    "are 3 models that share weights. After training the VAE model,\n",
    "the encoder can be used to generate latent vectors.\n",
    "The decoder can be used to generate MNIST digits by sampling the\n",
    "latent vector from a Gaussian distribution with mean = 0 and std = 1.\n",
    "\n",
    "# Reference\n",
    "\n",
    "[1] Kingma, Diederik P., and Max Welling.\n",
    "\"Auto-Encoding Variational Bayes.\"\n",
    "https://arxiv.org/abs/1312.6114\n",
    "'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from csv import reader\n",
    "\n",
    "# import\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.layers import Dropout\n",
    "# keras lambda layer\n",
    "from keras.models import Model\n",
    "# from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy,categorical_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "# from keras.layers import Input, Dense\n",
    "# from keras.models import Model\n",
    "import csv\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.misc import imread\n",
    "# import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "# import cv2\n",
    "\n",
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample epsilon = N(0,I)\n",
    "# z = z_mean + sqrt(var) * epsilon\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "# inputno = 0/0\n",
    "# inp11 = 0\n",
    "# out11 = 0\n",
    "\n",
    "# def getnewloss(x2):\n",
    "\n",
    "#     outputno = outputno + 1\n",
    "#     return binary_crossentropy(x1,x2)\n",
    "\n",
    "\n",
    "# def getloss(x1):\n",
    "#     # output = outputs[inputno]\n",
    "#     # inputindex = imindex[inputno]\n",
    "#     outputno = 0\n",
    "#     losses1 = tf.map_fn(lambda x : getnewloss(x),outputs)\n",
    "#     inputno = inputno + 1\n",
    "#     return tf.reduce_sum(losses1)\n",
    "\n",
    "def classcrossentropy(inputs,outputs):\n",
    "    loss = 0\n",
    "    i = 0\n",
    "\n",
    "    input1 = inputs[1]\n",
    "    output1 = outputs[0]\n",
    "    recon_loss = -tf.reduce_sum(\n",
    "    input1 * tf.log(1e-5+output1) + \n",
    "    (1-input1) * tf.log(1e-5+1-output1), \n",
    "    axis=1\n",
    ")\n",
    "    input2 = inputs[2]\n",
    "    output2 = outputs[1]\n",
    "    \n",
    "#     print(input2.shape)\n",
    "#     print(output2.shape)\n",
    "    \n",
    "#     print(inputs.shape)\n",
    "    recon_loss = recon_loss + categorical_crossentropy(input2,output2)\n",
    "    \n",
    "    \n",
    "    return recon_loss\n",
    "\n",
    "\n",
    "\n",
    "    # print(tf.shape(inputs))\n",
    "    # print(outputs.shape)\n",
    "    # print(inputs[0].shape)\n",
    "    # print(inputs[1].shape)\n",
    "    \n",
    "    # print(inputs.shape)\n",
    "    #\n",
    "    # return binary_crossentropy(inputs[1],outputs)\n",
    "    \n",
    "#     tf.map_fn(\n",
    "#     fn,\n",
    "#     elems,\n",
    "#     dtype=None,\n",
    "#     parallel_iterations=None,\n",
    "#     back_prop=True,\n",
    "#     swap_memory=False,\n",
    "#     infer_shape=True,\n",
    "#     name=None\n",
    "# )\n",
    "                                   \n",
    "    # inp11 = inputs[0]\n",
    "    # out11 = outputs                                                     \n",
    "    # iminput = inputs[0]\n",
    "    # imindex = inputs[1]\n",
    "    # indices = [i for i, x in enumerate(my_list) if x == \"whatever\"]\n",
    "    # outputs[:] = outputs[:].append(imindex)\n",
    "    # for rec in outputs:\n",
    "        # loss = rec\n",
    "    # outputno = 0\n",
    "    # inputno = 0\n",
    "    # losses = tf.map_fn(lambda x : getloss(x),)\n",
    "\n",
    "    # return tf.reduce_sum(losses,axis = 1)\n",
    "\n",
    "    # inputs = inputs[0]\n",
    "\n",
    "    # epsilon = 1e-10\n",
    "    # epsilon = epsilon*np.ones((128,2048))\n",
    "\n",
    "    # recon_loss = -tf.reduce_sum(\n",
    "    #     inputs * tf.log(1e-10+outputs) + \n",
    "    #     (1-inputs) * tf.log(1e-10+1-outputs), \n",
    "    #     axis=1\n",
    "    # )\n",
    "\n",
    "    # recon_loss = tf.reduce_mean(recon_loss)\n",
    "\n",
    "    # Latent loss\n",
    "    # KL divergence: measure the difference between two distributions\n",
    "    # Here we measure the divergence between \n",
    "    # the latent distribution and N(0, 1)\n",
    "    # latent_loss = -0.5 * tf.reduce_sum(\n",
    "    #     1 + z_log_sigma_sq - tf.square(z_mu) - \n",
    "    #     tf.exp(z_log_sigma_sq), axis=1)\n",
    "    # latent_loss = tf.reduce_mean(latent_loss)\n",
    "\n",
    "    # total_loss = recon_loss + latent_loss\n",
    "    # return recon_loss\n",
    "\n",
    "    # j = 0\n",
    "    # # return binary_crossentropy(inputs[0],outputs)\n",
    "    # inputim = inputs[0]\n",
    "    # inputlabel = inputs[1]\n",
    "\n",
    "    # for i in range(batch_size):\n",
    "    #     # j = 0\n",
    "    #     for j in range(batch_size):\n",
    "    #         # j+= 1\n",
    "    #         # input1 = inputim[i]\n",
    "    #         input2 = inputim[j]\n",
    "    #         k1 = inputlabel[i]\n",
    "    #         k2 = inputlabel[j]\n",
    "    #         output1 = outputs[i]\n",
    "    #         # print(k1)\n",
    "    #         # print(k2)\n",
    "    #         # if(k1 == k2):\n",
    "    #         loss = loss + binary_crossentropy(input2,output1)\n",
    "    #     # i+= 1\n",
    "    # return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(inputs1.shape)\n",
    "    # # if(runmode == \"single\"):\n",
    "    # # return binary_crossentropy(inputs,outputs)\n",
    "    \n",
    "\n",
    "    # i = 0\n",
    "    # for inputs in inputs1:\n",
    "    #     outputs = outputs1[i]\n",
    "    #     imlabel = 0\n",
    "    #     i1 = 0\n",
    "    #     for im1 in flowerlist:\n",
    "    #         # if(im1 == inputs):\n",
    "    #         if(np.array_equal(im1,inputs)):\n",
    "    #             imlabel = labels[i1]\n",
    "    #             break\n",
    "    #         i1 = i1+1\n",
    "    #     print(imlabel)\n",
    "    # #     for key in dict1:    \n",
    "    #     loss = 0\n",
    "    #     i1 = 0\n",
    "    #     for image1 in flowerlist:\n",
    "    #         if(labels[i1] == imlabel):\n",
    "    #             if(loss == 0):\n",
    "    #                 loss = binary_crossentropy(image1,outputs)\n",
    "    #             else:\n",
    "    #                 loss = loss + binary_crossentropy(image1,outputs)\n",
    "    #         i1 += 1\n",
    "    #     # return binary_crossentropy(inputs,outputs)\n",
    "    #     print(loss)\n",
    "    #     print(binary_crossentropy(image1,outputs))\n",
    "    #     i = i+1\n",
    "    # return K.sum(loss)\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=128,\n",
    "                 model_name=\"vae_mnist\"):\n",
    "    \"\"\"Plots labels and MNIST digits as a function of the 2D latent vector\n",
    "\n",
    "    # Arguments\n",
    "        models (tuple): encoder and decoder models\n",
    "        data (tuple): test data and label\n",
    "        batch_size (int): prediction batch size\n",
    "        model_name (string): which model is using this function\n",
    "    \"\"\"\n",
    "\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(x_test,\n",
    "                                   batch_size=batch_size)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "    filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "    # display a 30x30 2D manifold of digits\n",
    "    n = 30\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-4, 4, n)\n",
    "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = (n - 1) * digit_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# In[6]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.30657583e-01 0.00000000e+00 1.58262417e-01 ... 1.48387847e-03\n",
      "  5.16680665e-02 9.60000000e+01]\n",
      " [7.91267678e-02 4.74323779e-02 2.86131024e-01 ... 4.60444540e-01\n",
      "  9.41855609e-02 7.70000000e+01]\n",
      " [5.64596523e-03 0.00000000e+00 3.55518848e-01 ... 4.78732400e-03\n",
      "  4.17682201e-01 1.20000000e+01]\n",
      " ...\n",
      " [2.52421409e-01 9.14032012e-02 5.51894128e-01 ... 7.05158591e-01\n",
      "  1.47102714e-01 8.10000000e+01]\n",
      " [2.56720841e-01 0.00000000e+00 1.80523872e-01 ... 3.00223410e-01\n",
      "  1.79189116e-01 3.80000000e+01]\n",
      " [5.08076012e-01 0.00000000e+00 1.49886563e-01 ... 0.00000000e+00\n",
      "  4.74282265e-01 1.00000000e+02]]\n",
      "[[0.00000000e+00 0.00000000e+00 3.77382517e-01 ... 1.30591989e-02\n",
      "  1.29120678e-01 7.20000000e+01]\n",
      " [1.02947839e-01 4.27593058e-03 0.00000000e+00 ... 0.00000000e+00\n",
      "  5.99070592e-03 2.60000000e+01]\n",
      " [6.44188374e-02 1.50903082e-02 6.96491420e-01 ... 8.16476122e-02\n",
      "  2.00917661e-01 7.70000000e+01]\n",
      " ...\n",
      " [0.00000000e+00 3.18466011e-03 4.09572348e-02 ... 0.00000000e+00\n",
      "  7.83597771e-03 4.40000000e+01]\n",
      " [3.02856117e-01 0.00000000e+00 1.68044511e-02 ... 2.27049310e-02\n",
      "  6.66083455e-01 6.90000000e+01]\n",
      " [1.70454577e-01 0.00000000e+00 3.18993211e-01 ... 1.00299045e-02\n",
      "  4.09046859e-01 5.20000000e+01]]\n",
      "[72. 26. 77. 39. 89. 85. 44. 69. 52.]\n",
      "[ 96.  77.  12. ...  81.  38. 100.]\n"
     ]
    }
   ],
   "source": [
    "# In[4]:\n",
    "# folder = \"jpg\"\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "# dict1 = {}\n",
    "# mypath = \"/home/anurag/projects/VAEProj/102flowers/jpg\"\n",
    "# onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "# sort(onlyfiles)\n",
    "# onlyfiles.sort()\n",
    "filename = 'flowersXception.csv'\n",
    "\n",
    "featurestotal = load_csv(filename)\n",
    "# labels = labels[0]    \n",
    "# print(onlyfiles)\n",
    "# i1 = 1\n",
    "# seltol = 1300\n",
    "#seltol = 10\n",
    "# selected1 = 800\n",
    "# for selected1 in [200]:\n",
    "# samplpositive = 600\n",
    "#samplpositive = 10\n",
    "# featurestotal = []\n",
    "# i1 = 0\n",
    "# for image in onlyfiles:\n",
    "#     if(image[-3:] != \"jpg\"):\n",
    "#         continue\n",
    "#     # i1 = i1 + 1\n",
    "#     # print(\"efrffrwf\")\n",
    "\n",
    "#     im1 = mypath+\"/\"+ image\n",
    "#     # print(im1)\n",
    "#     # print(labels[i1])\n",
    "#     # im = imread(im1,cv2.COLOR_BGR2GRAY)\n",
    "#     im = imread(im1)\n",
    "#     im = im/float(255)\n",
    "#     # print(im)\n",
    "#     res = cv2.resize(im, dsize=(50,50), interpolation=cv2.INTER_CUBIC)\n",
    "#     #res = cv2.resize(im, dsize=(500,500))\n",
    "#     # res = im\n",
    "#     # k1\n",
    "\n",
    "\n",
    "#     k1 = np.reshape(res,-1)\n",
    "#     # np.append(k1,labels[i1])\n",
    "#     # print(k)\n",
    "#     k1 = list(k1)\n",
    "#     k1.append(labels[i1])\n",
    "#     # print(k1)\n",
    "\n",
    "# #     dict1[k1] = labels[i1] \n",
    "#     # print(k1.shape)\n",
    "#         # print(i1)\n",
    "#     print(i1)\n",
    "#     featurestotal.append(k1)\n",
    "#     i1 = i1+ 1\n",
    "#     # if(i1 == 85):\n",
    "#         # break\n",
    "\n",
    "\n",
    "\n",
    "# flowerlist = []\n",
    "\n",
    "rd.shuffle(featurestotal)\n",
    "# flowerlist.extend(featurestotal)\n",
    "\n",
    "# flowerlist contains the required entries\n",
    "\n",
    "\n",
    "\n",
    "x_train = featurestotal[:8180]\n",
    "x_test = featurestotal[8180:]\n",
    "\n",
    "\n",
    "# x_train = featurestotal[:4000]\n",
    "# x_test = featurestotal[4000:]\n",
    "\n",
    "\n",
    "# x_train = featurestotal[:400]\n",
    "# x_test = featurestotal[400:]\n",
    "\n",
    "\n",
    "x_train = np.array(x_train,dtype = float)\n",
    "x_test = np.array(x_test,dtype = float)\n",
    "\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "\n",
    "\n",
    "x_trainlabel = x_train[:,2048]\n",
    "x_train = x_train[:,0:2048]\n",
    "x_testlabel = x_test[:,2048]\n",
    "x_test = x_test[:,0:2048]\n",
    "\n",
    "print(x_testlabel)\n",
    "print(x_trainlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048,)\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros(2048,dtype = float)\n",
    " # = np.repeat(a[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "x_trainlabelsum = np.repeat(a[np.newaxis,:], 102,axis = 0)\n",
    "x_testlabelsum = np.repeat(a[np.newaxis,:], 102,axis = 0)\n",
    "print(x_trainlabelsum[0].shape)\n",
    "\n",
    "# x_testlabelsum = []\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "trainnum = np.zeros(102)\n",
    "testnum = np.zeros(102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96. 77. 12. 86.]\n",
      "[72. 26. 77. 39. 89. 85. 44. 69. 52.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# In[18]:\n",
    "trainonehotlabel = []\n",
    "testonehotlabel = []\n",
    "\n",
    "\n",
    "i = 0\n",
    "for fq in x_trainlabel:\n",
    "    image = x_train[i]\n",
    "    fq = int(fq)\n",
    "    # print(fq)\n",
    "    fq = fq-1\n",
    "#     print(fq)\n",
    "#     print(x_trainlabelsum[fq].shape)\n",
    "#     print(type(image))\n",
    "#     print(image.shape)\n",
    "#     print(x_trainlabelsum[fq])\n",
    "# #     print(type(image))\n",
    "#     print(image)\n",
    "    \n",
    "    x_trainlabelsum[fq] = np.add(x_trainlabelsum[fq],image)\n",
    "    trainnum[fq] = trainnum[fq] + 1\n",
    "    arr = np.zeros(102)\n",
    "    arr[fq] = 1\n",
    "    trainonehotlabel.append(arr)\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "i = 0\n",
    "for fq in x_testlabel:\n",
    "    fq = fq-1\n",
    "    im = x_test[i]\n",
    "    fq = int(fq)\n",
    "    x_testlabelsum[fq] = np.add(x_testlabelsum[fq],im)\n",
    "    testnum[fq] = testnum[fq] + 1\n",
    "\n",
    "    arr = np.zeros(102)\n",
    "    arr[fq] = 1\n",
    "    testonehotlabel.append(arr)\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "print(x_trainlabel[0:4])\n",
    "print(x_testlabel)\n",
    "\n",
    "\n",
    "trainonehotlabel = np.array(trainonehotlabel)\n",
    "testonehotlabel = np.array(testonehotlabel)\n",
    "print(trainonehotlabel)\n",
    "print(testonehotlabel)\n",
    "\n",
    "# exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = np.copy(x_train)\n",
    "x_test2 = np.copy(x_test)\n",
    "\n",
    "i = 0\n",
    "for d2 in x_trainlabel:\n",
    "    d2 = int(d2)\n",
    "    d2 = d2-1\n",
    "    x_train2[i] = x_trainlabelsum[d2]/(float(trainnum[d2]))\n",
    "    i = i+1\n",
    "\n",
    "i = 0\n",
    "for d2 in x_testlabel:\n",
    "    d2 = int(d2)\n",
    "    d2 = d2-1\n",
    "    x_test2[i] = x_testlabelsum[d2]/(float(trainnum[d2]))\n",
    "    i = i+1\n",
    "\n",
    "# x_train\n",
    "\n",
    "# x_trainlabel = np.array(x_trainlabel)\n",
    "# x_testlabel = np.array(x_testlabel)\n",
    "\n",
    "# x_train\n",
    "\n",
    "\n",
    "# print(classcrossentropy(x_train[0],x_train[1]))\n",
    "# MNIST dataset\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# In[19]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_im (InputLayer)   (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          1049088     encoder_input_im[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          262656      dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            1026        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            1026        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,313,796\n",
      "Trainable params: 1,313,796\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_samples (InputLayer)       (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               1536      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2048)              1050624   \n",
      "=================================================================\n",
      "Total params: 1,314,816\n",
      "Trainable params: 1,314,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "class1 (InputLayer)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               1536      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 102)               52326     \n",
      "=================================================================\n",
      "Total params: 53,862\n",
      "Trainable params: 53,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# image_size = x_train[0].shape[0]\n",
    "# print(image_size)\n",
    "original_dim = 2048\n",
    "# x_train = np.reshape(x_train, [-1, original_dim])\n",
    "# x_test = np.reshape(x_test, [-1, original_dim])\n",
    "# x_train = x_train.astype('float32') / 255\n",
    "# x_test = x_test.astype('float32') / 255\n",
    "# print(im)\n",
    "# network parameters\n",
    "input_shape = (original_dim, )\n",
    "# print(\"input_shape\")\n",
    "# print(input_shape)\n",
    "intermediate_dim = 512 # of original layers\n",
    "intermediate_dim1 = 512 # of extra layers\n",
    "classifierdim = 512 # of classifiers\n",
    "classifieroutputdim = 102\n",
    "\n",
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "# model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(30, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "# VAE model = encoder + decoder\n",
    "# build encoder model\n",
    "input1 = Input(shape=input_shape, name='encoder_input_im')\n",
    "input2 = Input(shape=input_shape, name='encoder_input_imsum')\n",
    "input3 = Input(shape=(classifieroutputdim,),name='encoder_input_labels')\n",
    "# inputs = Input(shape=1, name='encoder_input_label')\n",
    "# drop1 = Dropout(0.2)(input1)\n",
    "x = Dense(intermediate_dim, activation='relu')(input1)\n",
    "x = Dense(intermediate_dim1, activation='relu')(x)\n",
    "\n",
    "# x = Dense(intermediate_dim1, activation='relu')(x)\n",
    "# drop1 = Dropout(0.2)(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "inps = [input1,input2,input3]\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "\n",
    "# encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "# encoder = Model(inputs = [input1,input2], [z_mean, z_log_var, z], name='encoder')\n",
    "encoder = Model(inps, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "# plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n",
    "\n",
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_samples')\n",
    "\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "# drop2 = Dropout(0.2)(x)\n",
    "x = Dense(intermediate_dim1, activation='relu')(x)\n",
    "# x = Dense(intermediate_dim1, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "# plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n",
    "\n",
    "#building classifier models\n",
    "classifier_inputs = Input(shape=(latent_dim,), name=\"class1\")\n",
    "\n",
    "x = Dense(classifierdim,activation = 'relu')(classifier_inputs)\n",
    "# x = Dense(classifierdim,activation = 'relu')(x)  # additional layer\n",
    "classifier_output = Dense(classifieroutputdim,activation = 'softmax')(x)\n",
    "\n",
    "classifier = Model(classifier_inputs,classifier_output,name=\"classifier\")\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "# instantiate VAE model\n",
    "output1 = decoder(encoder(inps)[2])\n",
    "output2 = classifier(encoder(inps)[2]) # classifing on smaple values\n",
    "# output2 = classifier(encoder(inps)[0]) # classifing on z_means\n",
    "outputs = [output1,output2]\n",
    "\n",
    "vae = Model(inps, outputs, name='vae_mlp + classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_im (InputLayer)   (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input_imsum (InputLayer (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input_labels (InputLaye (None, 102)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 2), (None, 2 1313796     encoder_input_im[0][0]           \n",
      "                                                                 encoder_input_imsum[0][0]        \n",
      "                                                                 encoder_input_labels[0][0]       \n",
      "                                                                 encoder_input_im[0][0]           \n",
      "                                                                 encoder_input_imsum[0][0]        \n",
      "                                                                 encoder_input_labels[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 2048)         1314816     encoder[1][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Model)              (None, 102)          53862       encoder[2][2]                    \n",
      "==================================================================================================\n",
      "Total params: 2,682,474\n",
      "Trainable params: 2,682,474\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/anurag/.local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 8180 samples, validate on 9 samples\n",
      "Epoch 1/300\n",
      "8180/8180 [==============================] - 7s 859us/step - loss: 1529013.2350 - val_loss: 658096.2500\n",
      "Epoch 2/300\n",
      "8180/8180 [==============================] - 5s 566us/step - loss: 1386884.1315 - val_loss: 653106.2500\n",
      "Epoch 3/300\n",
      "8180/8180 [==============================] - 5s 573us/step - loss: 1358337.0756 - val_loss: 679147.8750\n",
      "Epoch 4/300\n",
      "8064/8180 [============================>.] - ETA: 0s - loss: 1348385.2679"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-288f7160b259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             validation_data=([x_test,x_test2,testonehotlabel], None))\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vae_mlp_mnist.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anurag/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/anurag/.local/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anurag/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anurag/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anurag/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# inputs = Input(shape=input_shape, name='encoder_input')\n",
    "# x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "# z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "# z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# # use reparameterization trick to push the sampling out as input\n",
    "# # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# # instantiate encoder model\n",
    "# encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "# encoder.summary()\n",
    "# # plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n",
    "\n",
    "# # build decoder model\n",
    "# latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "# x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "# outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "\n",
    "# # instantiate decoder model\n",
    "# decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "# decoder.summary()\n",
    "# # plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n",
    "\n",
    "# # instantiate VAE model\n",
    "# outputs = decoder(encoder(inputs)[2])\n",
    "# vae = Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # dict1 = {}\n",
    "    kllosswt = 1;\n",
    "#     parser = argparse.ArgumentParser()\n",
    "\n",
    "#     help_ = \"Load h5 model trained weights\"\n",
    "#     parser.add_argument(\"-w\", \"--weights\", help=help_)\n",
    "#     help_ = \"Use mse loss instead of binary cross entropy (default)\"\n",
    "#     parser.add_argument(\"-m\",\n",
    "#                         \"--mse\",\n",
    "#                         help=help_, action='store_true')\n",
    "#     args = parser.parse_args()\n",
    "    models = (encoder, decoder)\n",
    "    # data = (x_test, y_test)\n",
    "\n",
    "# here1\n",
    "    # VAE loss = mse_loss or xent_loss + kl_loss\n",
    "    \n",
    "    # runmode = input(\"single or class encoder \")\n",
    "    # z33 = np.identity(1000)\n",
    "\n",
    "\n",
    "#     if args.mse:\n",
    "#         reconstruction_loss = mse(inputs, outputs)\n",
    "#     else:\n",
    "    reconstruction_loss = classcrossentropy(inps,\n",
    "                                              outputs)\n",
    "\n",
    "    reconstruction_loss *= original_dim\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss = kl_loss*-0.5*kllosswt\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='adam')\n",
    "    vae.summary()\n",
    "    # plot_model(vae,\n",
    "               # to_file='vae_mlp.png',\n",
    "               # show_shapes=True)\n",
    "\n",
    "#     if args.weights:\n",
    "#         vae.load_weights(args.weights)\n",
    "#     else:\n",
    "        # train the autoencoder\n",
    "    vae.fit([x_train,x_train2,trainonehotlabel],\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=([x_test,x_test2,testonehotlabel], None))\n",
    "    vae.save_weights('vae_mlp_mnist.h5')\n",
    "\n",
    "\n",
    "\n",
    "    # for i in test2\n",
    "    # plot_results(models,\n",
    "                 # data,\n",
    "                 # batch_size=batch_size,\n",
    "                 # model_name=\"vae_mlp\")\n",
    "\n",
    "    encoder, decoder = models\n",
    "    # encoder, decoder = models\n",
    "    x_test, y_test = [x_train,x_train2],x_trainlabel\n",
    "    # os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    # filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(x_test,\n",
    "                                   batch_size=batch_size)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    # plt.savefig(filename)\n",
    "    plt.show()\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
