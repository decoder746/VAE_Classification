
Tip try adding the following attributes to your arrays to get more information about the memory layout, the length of one array element in bytes and the total consumed bytes by the arrayâ€™s elements with the flags, itemsize, and nbytes attributes. You can test this out in the IPython console in the DataCamp Light chunk above!

labels.index(label) //array index of value

# Import the `transform` module from `skimage`
from skimage import transform 

# Rescale the images in the `images` array
images28 = [transform.resize(image, (28, 28)) for image in images]

1. what is L1 and L2 regularization
2. what is batch regularization
	batch normalization in place of dropout for CNN and droupot never placed between convolutions
	https://towardsdatascience.com/dont-use-dropout-in-convolutional-networks-81486c823c16

3. read more about resnet

4. feature extraction and various CNN's comparision

5. Maximum Mean Discrepancy (MMD) approach

6. why is using Xception with pre-trained weights the best idea.


without rgb
4000/4000 [==============================] - 5s 1ms/step - loss: 4045668.4920 - val_loss: 4169700.9333
7000/7000 [==============================] - 7s 998us/step - loss: 4041802.2040 - val_loss: 3377982.7454

with rgb
7000/7000 [==============================] - 12s 2ms/step - loss: 34616386.2217 - val_loss: 29167616.4054
8150/8150 [==============================] - 9s 1ms/step - loss: 34619925.7413 - val_loss: 29075194.0000
dropout = 0.5
7000/7000 [==============================] - 9s 1ms/step - loss: 34789299.1863 - val_loss: 28738109.7140
7000/7000 [==============================] - 10s 1ms/step - loss: 34549514.2446 - val_loss: 28346070.6526


try on kaggle with 1e-[6-9]
